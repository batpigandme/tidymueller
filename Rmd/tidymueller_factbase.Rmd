---
title: "Tidy Mueller: Factbase edition"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Using data from Factbase's _The Mueller Report: 18 April, 2019_ <https://f2.link/mr-sheet>. Big ups to Garrick Aden-Buie's extraction of the report available here: [The Redacted, Text-Extracted Mueller Report](https://www.garrickadenbuie.com/blog/redacted-text-extracted-mueller-report/).

```{r libraries}
library(tidyverse)
library(ggpage)
library(tidytext)
library(stringr)
```


```{r read-mueller}
mueller_report <- read_csv(here::here("data", "factbase_mueller_report.csv")) %>%
  select(Page, Text) %>%
  rename_all(tolower)
```

```{r tidy-mueller}
# tidy texting ------------------------------------------------------------
tidy_mueller <- mueller_report %>%
  unnest_tokens(word, text)

# remove stop words
data(stop_words)

tidy_mueller <- tidy_mueller %>%
  anti_join(stop_words)

mueller_word_count <- tidy_mueller %>%
  count(word, sort = TRUE) %>%
  filter(!str_detect(word, "[0-9]")) # remove numbers

```

[Watergate Special Prosecution Force Report](https://archive.org/stream/WatergateSpecialProsuectionForceReport/Watergate%20Special%20Prosuection%20Force%20Report_djvu.txt") via Internet Archive.

```{r}
# read in watergate special prosecution force report ----------------------
# source: https://archive.org/stream/WatergateSpecialProsuectionForceReport/Watergate%20Special%20Prosuection%20Force%20Report_djvu.txt"
watergate_report <- read_csv(here::here("data", "watergate_report.csv"))

tidy_watergate <- watergate_report %>%
  unnest_tokens(word, text)

tidy_watergate <- tidy_watergate %>%
  anti_join(stop_words)

watergate_word_count <- tidy_watergate %>%
  count(word, sort = TRUE) %>%
  filter(!str_detect(word, "[0-9]"))
```

```{r fig.width=10, fig.height=8}
# following: https://www.tidytextmining.com/tidytext.html#word-frequencies

# remove page bc we don't have it for watergate
tidy_mueller <- tidy_mueller %>%
  select(-page)

tidy_reports <- bind_rows(mutate(tidy_mueller, report = "Mueller"),
                    mutate(tidy_watergate, report = "Watergate")) %>%
  filter(!str_detect(word, "[0-9]"))

# following: https://www.tidytextmining.com/twitter.html#word-frequencies-1
raw_frequency <- tidy_reports %>%
  group_by(report) %>%
  count(word, sort = TRUE) %>%
  left_join(tidy_reports %>%
              group_by(report) %>%
              summarise(total = n())) %>%
  mutate(freq = n/total)

frequency <- raw_frequency %>%
  select(report, word, freq) %>%
  spread(report, freq) %>%
  arrange(Mueller, Watergate) %>%
  filter(word != "sessions")


# plot relative frequencies -----------------------------------------------
library(scales)

ggplot(frequency, aes(Mueller, Watergate)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  geom_abline(color = "red") +
  hrbrthemes::theme_ipsum_rc() +
  labs(title = "Word frequencies in Mueller vs. Watergate Reports",
       subtitle = "Text from Mueller Report (2019), Watergate Special Prosecution Force Report (1975)",
       caption = "by @dataandme")
```

